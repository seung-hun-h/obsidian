# 1. 토픽 작업
**kafka-topics.sh**는 카프카 토픽 관련 작업을 수행하기 위한 도구다
## 1. 토픽 생성하기
```sh
./bin/kafka-topics.sh --bootstrap-server <connection-string>:<port> --create --topic <string> --replication-factor <integer> --partitions <integer>
```

- `--topic`
	- 생성하려는 토픽이름
- `--replication-factor`
	- 클러스터 안에서 유지되어야 할 레플리카의 개수
- `--partitions`
	- 토픽에서 생성할 파티션의 개수
#### 선택 옵션
- `--if-exists`
	- alter 명령과 함께 사용하는 것은 권장하지 않는다. 이 인수를 사용하면 변경되는 토픽이 존재하지 않을 때 에러가 리턴되지 않기 때문이다.
- `--if-not-exists`
	- 토픽 생성을 자동화할 경우 같은 이름의 토픽의 이름이 있을 때 에러를 발생하지 않기 위해 `--if-not-exists` 옵션을 추가해준다. 
## 2. 토픽 목록 조회하기
```sh
./bin/kafka-topics.sh --bootstrap-server <connection-string>:<port> --list
```
- `--list`
	- 클러스터내 모든 토픽을 조회한다
#### 선택 옵션
- `--exclude-internal`
	- `__`로 시작하는 토픽을 제외할 수 있다
## 3. 토픽 상세 내역 조회 하기
```sh
./bin/kafka-topics.sh --bootstrap-server <connection-string>:<port> --describe --topic <string>
```
- `--describe`
	- 토픽을 상세 조회한다
#### 선택 옵션
- 아래 선택 옵션은 `--list`와 함께 사용할 수 없고, 대개 `--topic` 인수를 지정하지 않고 사용한다
- `--topics-with-overrides`
	- 클러스터 기본값을 재정의한 것이 있는 토픽들을 조회한다
- `--exclude-internal`
	- `__`로 시작하는 토픽들을 제외하여 조회한다
- `--under-replicated-partitions`
	- 1개 이상의 리플리카가 리더와 동기화되지 않고 있는 모든 파티션을 보여준다
	- 클러스터 정비, 설치 혹은 리밸런스 과정에서 불완전 복제 파티션이 발생할 수도 있기에 꼭 나쁜건 아니지만 주의를 기울일 필요는 있다
- `--at-min-isr-partitions`
	- 레플리카 수가 인-싱크 레플리카 최소값(`min.insync.replicas`)과 같은 모든 파티션을 보여준다
- `--under-min-isr-partitions`
	- ISR의 수가 쓰지 작업 성공을 위해 필요한 최소 레플리카 수에 미달하는 모든 파티션을 보여준다
- `--unavailable-partitions`
	- 리더가 없는 모든 파티션을 보여준다
## 4. 파티션 추가하기
```sh
./bin/kafka-topics.sh --bootstrap-server <connection-string>:<port> --alter --topic <string> --partitions <integer>
```
- `--alter`
	-  토픽의 설정을 변경한다
- `--partitions`
	-  변경할 파티션의 수를 지정한다
## 5. 파티션 개수 줄이기
- 파티션의 수는 **줄일 수 없기** 때문에 유의한다. 줄이기 위해서는 토픽을 제거한 후 재생성하거나, 다른 토픽으로 전환해야 한다
## 6. 토픽 삭제하기
```sh
./bin/kafka-topics.sh --bootstrap-server <connection-string>:<port> --delete --topic <string>
```
- `--delete`
	- 토픽을 삭제한다
# 2. 컨슈머 그룹
**kafka-consumer-groups.sh**는 카프카 컨슈머 그룹 관련 작업을 하기 위한 도구다
## 1. 컨슈머 그룹 목록 및 상세 내역 조회하기
```sh
./bin/kafka-consumer-groups.sh --bootstrap-server <connection-string>:<port> --list

./bin/kafka-consumer-groups.sh --bootstrap-server <connection-string>:<port> --describe --group <string>
```
## 2. 컨슈머 그룹 삭제하기
```sh
./bin/kafka-consumer-groups.sh --bootstrap-server <connection-string>:<port> --delete --group <string>
```
## 3. 오프셋 관리
### 1. 오프셋 내보내기
```sh
./bin/kafka-consumer-groups.sh --bootstrap-server <connection-string>:<port> --export --group <string> --topic <string> --reset-offsets --to-current --dry-run > offsets.csv
```
- `--dry-run`
	- 명령이 실행되기전 어떤 작업이 수행될 지 출력만 해준다
- `--reset-offsets`
	- 파티션의 오프셋을 재설정 하는데 사용된다
- `--export`
	-  구성 정보를 내보낸다
### 3. 오프셋 가져오기
```sh
./bin/kafka-consumer-groups.sh --bootstrap-server <connection-string>:<port> --reset-offsets --group <string> --from-file <file> --execute
```
- `--from-file`
	- 오프셋 정보를 가져올 파일을 지정한다
- `--exeucte`
	- 오프셋 재설정을 실행한다
# 3. 동적 설정 변경
- 동적 설정이란 클러스터를 끄거나 재설치할 필요 없이 실행 중에 동적으로 바꿀 수 있는 설정이다
- 동적 설정 가능한 범주
	- 토픽
	- 브로커
	- 사용자
	- 클라이언트
- 동적으로 재정의 가능한 설정은 버전마다 늘어날 수 있으므로, 카프카 버전과 동일한 툴을 사용하는 것이 좋다

## 1. 동적으로 설정 변경하기
```sh
./bin/kafka-config.sh --bootstrap-server <connection-string>:<port> --alter --entity-type <string> --entity-name <string> --add-config {key}={value}, ...
```
- `--entity-type`
	- 동적 설정 대상 범주를 지정한다
- `--entity-name`
	- 동적 설정 대상 범주의 특정 이름을 지정한다
- `--add-config`
	- 설정을 추가한다
**설정 가능한 토픽 키**:  https://kafka.apache.org/documentation/#dynamicbrokerconfigs

## 2. 재정의된 설정 상세 조회하기
```sh
./bin/kafka-configs.sh --bootstrap-server <connection-string>:<port> --describe --entity-type <string> --entity-name <string> 
```
- 재정의된 값만 보여줄 뿐, 클러스터 기본값을 따르는 설정은 보여주지 않는다
## 3. 재정의된 설정 삭제하기
```sh
./bin/kafka-configs.sh --bootstrap-server <connection-string>:<port> --describe --entity-type <string> --entity-name <string> --delete-config <string>
```

# 4. 쓰기 작업과 읽기 작업
- 수동으로 메시지를 읽고 쓰기 위해 `kafka-console-consumer.sh`, `kafka-console-producer.sh`를 제공한다
## 1. 콘솔 프로듀서
```sh
./bin/kafka-console-producer.sh --bootstrap-server <connection-string>:<port> --topic <string> 
> Message 1
> Messate 2
```

### 1. 프로듀서 설정 옵션 사용하기
- `--producer.config {설정 파일}`로 프로듀서 설정 파일을 지정하는 방법과 `--producer-property {키}={값}` 형태로 명령줄에 인수로 전달하는 방법이 있다

```sh
./bin/kafka-console-producer.sh --bootstrap-server <connection-string>:<port> --topic <string> --producer-property <option> <value>
```
- 주로 사용하는 option
	- `--batch-size`
		- 한 번에 전달되어야 할 메시지의 수
	- `--timeout`
		- 프로듀서가 비동기 모드로 동작중일 때, 메시지 배치를 쓰기 전에 기다리는 최대 시간
	- `--compression-code`
		- 메시지를 쓸 때 사용할 압축 코덱
	- `--sync`
		- 메시지를 동기적으로 작성
### 2. 읽기 옵션
```sh
cat messages.txt | kafka-console-producer.sh \
--bootstrap-server localhost:9092 \
--topic my-topic \
--property ignore.error=true \
--property parse.key=true \
--property key.separator=":" \
```
- `--property`를 사용한다
- 자주 사용하는 option
	- `ignore.error`
		- 이 값이 false일 때, `parse.key`가 true이고 키 구분자가 지정되어 있지 않은 경우 예외가 발생한다
	- `parse.key`
		-  키 값을 항상 `null`로 고정하고 싶다면 false로 잡아준다
	- `key.separator`
		- 키와 밸류를 구분할 때 사용하는 구분자이다
## 2. 콘솔 컨슈머
```sh
./bin/kafka-console-consumer.sh --bootstrap-server <connection-string>:<port> --topic <string> --from-beginning
```
- 어떤 토픽에서 메시지를 가져올 지 지정하는 옵션은 `--topic`, `--whitelist` 두가지가 있다
	- `--topic`: 특정 토픽을 지정한다
	- `--whiltelist`: 정규식을 지정하여 다수의 토픽을 지정한다
### 1. 컨슈머 설정 옵션 사용하기
- `--consumer.config {설정 파일}`로 프로듀서 설정 파일을 지정하는 방법과 `--consumer-property {키}={값}` 형태로 명령줄에 인수로 전달하는 방법이 있다
- `--formatter {class name}`
	- `kafka.tools.DefaultMessageFormatter`: 기본 포매터
	- `kafka.tools.LoggingMessageFormatter`: 로거를 사용해서 메시지를 출력한다. INFO 레벨이며 타임스탬프, 키, 밸류를 포함한다
	- `kafka.tools.ChecksumMessageFormatter`: 메시지의 체크섬만 출력한다
	- `kafka.tools.NoOpMessageFormatter`: 메시지를 읽어오되 아무것도 출력하지 않는다

```sh
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
--whitelist 'my.*' --from-beginning \
--formatter kafka.tools.ChecksumMessageFormatter
```

- `--from-beginning`
	- 지정된 토픽의 가장 오래된 메시지를 읽어온다
- `--max-messages {number}`
	- 종료되기 전 읽어올 최대 메시지 수
- `--partition {number}`
	- 지정된 ID의 파티션에서만 읽어 온다
- `--offset`
	- 읽어오기 시작할 오프셋
- `--skip-message-on-error`
	- 메시지에 에러가 있을 경우 실행을 중단하는 것이 아니라 넘어간다. 디버깅할 때 좋다
### 2. 오프셋 토픽 읽어오기
- 콘솔 컨슈머를 사용해서 `__consumer_offsets` 내부 토픽을 읽어오면 된다
- `kafka.coordinator.group.GroupMetadataManager$OffsetsMessageFormatter`를 사용한다
```sh
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
--topic __consumer_offsets --from-beginning --max-messages 1
--formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter"
--consumer-property exclude.internal.topics=false
```
# 5. 파티션 관리
## 1. 선호 레플리카 선출
- 선호 레플리카란 레플리카 목록에 있는 첫 번째 인-싱크 레플리카를 말한다
- 브로커가 중단되거나 네트워크에 문제가 생기면 선호 레플리카가 리더가 아닐 수 있다
	- 크루즈 컨트롤과 같은 서드파티 오픈소스 툴이나 자동 리더 밸런싱 기능을 켜놓으면 이전에 리더 역할을 맡고 있던 레플리카가 다시 리더가 될 수 있다
- 브로커간 부하를 고르게 분산시키기 위해 선호 레플리카 선출을 실행 시킬 수 있다

```sh
./bin/kafka-leader-election.sh --bootstrap-server localhost:9092 \
--election-type PREFERRED \
--all-topic-partitions
```
- `--eletion-type`
	- 선출 유형을 지정한다
- `--all-topic-partitions`
	- 모든 토픽의 모든 파티션에 대해 수행한다

```json
{
	"partitions": [
		{
			"partition": 1,
			"topic": "my-topic"
		},
		{
			"partition": 2,
			"topic": "foo"
		}
	]
}
```

```sh
./bin/kafka-leader-election.sh --bootstrap-server localhost:9092 \
--election-type PREFERRED \
--path-to-json-file partitions.json
```
- `--topic`, `--partition` 옵션을 통해 특정 토픽의 특정 파티만 대상으로 지정할 수도 있다
- `partitions.json`과 같이 JSON 파일을 지정해주면 된다

## 2. 파티션 레플리카 변경하기
- 파티션의 레플리카 할당을 수동으로 변경하는 경우
	- 자동으로 리더 레플리카를 분산시켜도 브로커간 부하가 불균등할 때
	- 브로커가 내려가서 파티션이 불완전 복제되고 있을 때(언클린 리더 선출)
	- 새로 추가된 브로커에 빠르게 부하를 분산시켜주고 싶을 때
	- 토픽의 복제 팩터를 변경해주고 싶을 때
- `kafka-reassign-partitions.sh`를 사용한다
	- 이동시킬 파티션의 목록을 생성하는 것과 생성된 안을 실행시키는 두 단계로 나뉜다
	- 그리고 진행 상황을 확인할 수 있다
#### 1. 이동안 생성
```json
{
	"topics": [
		{
			"topic": "foo1"
		},
		{
			"topic": "foo2"
		}
	],
	"version": 1
}
```

```sh
./bin/kafka-reassign-partitions.sh --bootstrap-server localhost:9092 \
--topic-to-move-json-file topics.json \
--broker-list 5,6 --generate
```

```sh
{
	"version": 1,
	"partitions": [
		{"topic": "foo1", "partition":2, "replicas":[1,2]},
		{"topic": "foo1", "partition":0, "replicas":[3,4]},
		{"topic": "foo2", "partition":2, "replicas":[1,2]},
		{"topic": "foo2", "partition":0, "replicas":[3,4]},
		{"topic": "foo1", "partition":1, "replicas":[2,3]},
		{"topic": "foo2", "partition":1, "replicas":[2,3]},
	]
}
Proposed partition reassignment configuration
{
	"version": 1,
	"partitions": [
		{"topic": "foo1", "partition":2, "replicas":[5,6]},
		{"topic": "foo1", "partition":0, "replicas":[5,6]},
		{"topic": "foo2", "partition":2, "replicas":[5,6]},
		{"topic": "foo2", "partition":0, "replicas":[5,6]},
		{"topic": "foo1", "partition":1, "replicas":[5,6]},
		{"topic": "foo2", "partition":1, "replicas":[5,6]},
	]
}
```

- 위 명령을 실행하면 두 개의 JSON 컨텐츠(기존안, 이동안)가 출력된다
	- 각각 `revert-assignment.json`, `expand-cluster-reassignment.json`이라 부르자
- `--topic-to-move-json-file`
	- 이동시킬 파티션의 목록을 만들기 위한 토픽이 작성된 파일을 지정한다
- `--broker-list`
	- 이동시킬 브로커를 지정한다
- `--generate`
	- 파일을 생성한다
#### 2. 이동안 실행
```sh
./bin/kafka-reassign-partitions.sh --bootstrap-server localhost:9092 \
--reassignment-json-file expand-cluster-reassignment.json \
--execute
```
- `--reassignment-json-file`
	- 파티션 이동 목록 파일을 지정한다
- `--execute`
	- 파티션 이동을 실행한다
##### 선택 옵션
- `--additional`
	- 지정된 재할당 작업이 현재 진행중인 재할당 작업에 추가되도록 한다
- `--disable-rack-aware`
	- 랙 인식 기능으로 파티션 이동안의 결과를 사용할 수 없을 수 있다. 이 옵션으로 랙 인식 기능을 끌 수 있다
- `--throttle`
	- 파티션 재할당은 일정하게 유지되던 메모리, 페이지 캐시 사용량, 네트워크, 디스크 I/O를 변화 시키는 만큼 클러스터에 큰 영향을 미친다.  파티션 이동에 스로틀링을 걸어서 이 문제를 방지할 수 있다
```sh
kafka-reassign-partitions.sh \
--bootstrap-server localhost:9092 \
--reassignment-json-file reassignment-plan.json \
--execute \
--throttle 1048576
```
- 위 명령은 데이터 이동 속도를  1MB/s로 제한 한다
#### 3. 진행 상황 확인
```sh
./bin/kafka-reassign-partitions.sh --bootstrap-server localhost:9092 \
--reassignment-json-file expand-cluster-reassignment.json \
--verify
```
- 위 명령으로 현재 진행 상황을 확인한다

### 1. 복제 팩터 변경하기
1. **재할당 계획 생성**: 기존 복제본을 포함해 새로운 복제 팩터를 반영한 계획을 작성.
```json
{
  "topics": [
    {"topic": "example-topic"}
  ]
}
```

```sh
./bin/kafka-reassign-partitions.sh \
--bootstrap-server localhost:9092 \
--generate \
--topics-to-move-json-file topics-to-move.json \
--broker-list "1,2,3" \
> reassignment-plan.json
```

```json
{
  "version": 1,
  "partitions": [
    {
      "topic": "example-topic",
      "partition": 0,
      "replicas": [1, 2, 3],
      "log_dirs": ["any", "any", "any"]
    },
    {
      "topic": "example-topic",
      "partition": 1,
      "replicas": [2, 3, 1],
      "log_dirs": ["any", "any", "any"]
    }
  ]
}
```
2. **재할당 계획 실행**: Kafka 클러스터에 계획을 적용.
```sh
kafka-reassign-partitions.sh \
--bootstrap-server localhost:9092 \
--reassignment-json-file reassignment-plan.json \
--execute
```
3. **진행 상태 확인**: 재할당 완료 여부 확인.
```sh
kafka-reassign-partitions.sh \
--bootstrap-server localhost:9092 \
--reassignment-json-file reassignment-plan.json \
--verify
```
### 2. 레플리카 재할당 취소하기
- 현재 진행중인 재할당 과정을 취소하고 싶은 경우 `--cancle` 옵션을 사용한다
## 3. 로그 세그먼트 덤프 뜨기
- 토픽 내 특정 메시지가 오염되어 컨슈머가 처리할 수 없는 경우, 특정 메시지의 내용물을 열어봐야 한다
- `kafka-dump-log.sh`는 파티션의 로그 세그먼트들을 열어볼 때 사용하는 툴이다

```bash
./bin/kafka-dump-logs.sh --files <log-file>... 
```
- https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-dump-log-sh
## 4. 레플리카 검증
- 클러스터 전체에 걸쳐 토픽 파티션의 레플리카들이 모두 동일하다는 점을 확인하기 위해서  `kafka-replica-verification.sh`를 사용한다
- `kafka-replica-verification.sh`는 주어진 토픽의 모든 레플리카로부터 메시지를 읽고, 모든 레플리카가 해당 메시지를 가지고 있음을 확인하고, 주어진 파티션의 최대 랙 값을 출력한다
	- 가장 오래된 오프셋에서부터 모든 메시지를 읽고, 각 파티션의 모든 레플리카에 대해 병렬로 내용물을 읽어오므로 주의해야 한다
```bash
./bin/kafka-replica-verification.sh --broker-list 1.2.3.4:9092,5.6.7.8:9092 --topic-white-list my.*
```
# 6. 기타 툴
- `kafka-acls.sh`
	- 카프카 클라이언트에 대한 접근 제어를 관리한다
- `kafka-mirror-maker.sh`
	- 데이터 미러링용으로 사용한다
- `kafka-broker-api-versions.sh`
	- 카프카 버전을 업그레이드 하는 과정에서 호환성 문제를 확인하기 위해 사용되는 API 요소들의 서로 다른 버전을 확인할 수 있다
# 7. 안전하지 않은 작업
## 1. 클러스터 컨트롤러 이전하기
- 컨트롤러 선출은 주키퍼의 **Ephermeral 노드**를 사용해서 자동으로 이루어진다
- 오작동하고 있는 클러스터나 브로커에 대해 트러블 슈팅 중인 경우 컨트롤러 역할을 하는 브로커를 끄는 대신 역할을 이전할 수도 있다
- 컨트롤러를 강제로 옮기려면 `/admin/controller` 노드를 수동으로 삭제하면된다
	- 랜덤으로 새로운 컨트롤러가 지정된다
## 2. 삭제될 토픽 제거하기
- 카프카의 토픽 삭제 요청이 왔을 때 삭제 요청이 멈출 수 있는 경우가 있다
	- 요청을 하는 프로세스의 입장에서 클러스터에 토픽 삭제 기능이 켜져있는지 알 수 없다. 토픽 삭제 기능이 꺼져있는 클러스터의 토픽을 삭제하려고 한다
	- 삭제 요청이 들어온 후, 요청이 처리되기 전 1개 이상의 레플리카가 하드웨어 문제로 오프라인 상태가되어 삭제 작업이 완료되지 못한다
- 멈춤 상태에서 빠져나오고 싶다면, 주키퍼에서 `/admin/delete_topic/{topic}` 노드를 지운다
	- 아직 완료되지 않은 삭제 요청이 삭제된다
## 3. 수동으로 토픽 삭제하기
1. 클러스터의 모든 브로커를 내린다
2. 주키퍼의 카프카 클러스터 설정 노드 아래에서 `/brokers/topics/{topic}`을 삭제한다. 자식 노드를 먼저 삭제해야 한다
3. 각 브로커의 로그 디렉토리에서 토픽에 해당하는 파티션의 디렉토리를 삭제한다. `{topic}-{int}` 형식이다
4. 모든 브로커를 재시작한다

