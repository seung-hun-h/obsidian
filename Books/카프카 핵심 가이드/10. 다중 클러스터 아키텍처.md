다양한 상황에서 카프카 클러스터간 데이터를 복제해야 하는 경우가 있다. 카프카에서는 클러스터간 데이터 복제를 **미러링**이라 한다
# 1. 클러스터간 미러링 활용 사례
**지역 및 중앙 클러스터**
- 기업이 지리적으로 분산된 데이터센터를 가지고 있고, 각각의 데이터센터에 카프카 클러스터가 설치된 경우다
- 어떤 애플리케이션은 여러 데이터센터에 저장된 데이터를 필요로 한다. 
**고가용성과 재해 복구**
- 한 클러스터의 데이터를 미러링하여 다른 클러스터에 두면, 한 클러스터가 어떠한 이유로 동작하지 않을 때 즉시 다른 클러스터를 투입할 수 있다
**규제**
- 국가, 지역별로 다른 법적, 규제적 요구 조건을 따르기 위해 카프카 클러스터별로 서로 다른 설정과 정책을 시행해야 할 수 있다
**클라우드 마이그레이션**
- 사내 데이터 센터와 클라우드 환경을 모두 사용하는 경우, 클라우드에 배포된 애플리케이션이 온프레미스 데이터베이스에 저장된 데이터를 필요로 할 수도 있다
**엣지 클러스터로부터의 데이터 집적**
- 여러 산업에서는 연결성이 제한된 소형기기를 사용하여 데이터를 생성한다
- 자원이 한정적인 엣지 클러스터를 대신해 가용성이 높은 집적용 클러스터를 사용한다면 엣시 클러스터의 연결성, 가용성, 지속성의 요구조건을 낮추는데 도움이 된다
# 2. 다중 클러스터 아키텍처
## 1. 데이터센터간 통신의 현실적 문제들
데이터센터간 통신에는 아래와 같은 문제점이 있기 때문에 애플리케이션이 매번 데이터를 요청하는 것 보다는 각 데이터센터에 카프카 클러스터를 설치하여 미러링 하는 편이 낫다

**높은 지연**
- 클러스터간 물리적 거리 멀어지거나 네트워크 홉 개수가 늘어나면 지연이 늘어난다
**제한된 대역폭**
- 단일 데이터센터의 대역폭 보다 데이터센터 간 네트워크 대역폭이 훨씬 낮다
**더 높은 비용**
- 서로 다른 데이터센터간 통신에 더 많은 비용이 든다
	- 더 많은 네트워크 인프라(해저 케이블, 라우터 등등) 사용
	- 신뢰성있는 데이터 전달을 위한 고급 네트워크 기능 사용
## 2. 허브-앤-스포크 아키텍처
- 여러개의 로컬 카프카 클러스터와 한 개의 중앙 카프카 클러스터가 있는 아키텍처
- 로컬 카프카 클러스터 -> 중앙 카프카 클러스터의 단방향 통신이 이루어진다
**장점**
- 각각의 데이터센터에서 생성된 이벤트가 중앙에 단 한 번만 미러링된다
- 단방향으로 미러링이 이루어지고, 컨슈머는 항상 같은 클러스터에서 데이터를 읽기 떄문에 통해 배포, 설정, 모니터링이 간편해진다
**단점**
- 한 로컬 데이터센터에서 다른 로컬 데이터센터의 데이터를 읽을 수 없다
## 3. 액티브-액티브 아키텍처
- 2개 이상의 데이터센터가 전체 혹은 일부의 데이터를 공유하며, 각 데이터센터가 모두 읽기와 쓰기를 수행할 수 있는 아키텍처
- 양 방향 미러링이 이루어진다. 
**장점**
- 인근 데이터센터에서 사용자들의 요청을 처리할 수 있다
- 한 데이터센터에 문제가 발생하면 바로 인근의 데이터센터에서 요청을 처리할 수 있으므로 회복 탄력성이 좋다
**단점**
- 데이터를 여러 위치에서 읽고 쓰면서 발생하는 충돌을 피하기 어렵다
	- 데이터 충돌을 피할 수 없음을 인지하고, 데이터 충돌이 발생했을 때 해결할 수 있는 규칙을 만들어야 한다
- 순환 미러링이 발생할 수 있다
	- 서로 다른 데이터센터의 토픽 혹인 네임스페이스를 분리한다
- 데이터센터간 데이터 일관성을 유지하기 어렵다
## 4. 액티브-스탠바이 아키텍처
- 한 데이터센터에서 요청을 처리하고 다른 데이터센터는 요청 처리 중인 데이터센터에 문제가 발생한 것을 대비하여 미러링만 수행한다. 
**장점**
- 설치가 간단하다. 두 번째 클러스터를 설치한 뒤 첫 번째 클러스터를 미러링하는 프로세스를 설치하기만 하면 된다
**단점**
- 스탠바이 클래스터가 미러링만 하고 요청을 처리하지 않는다
- 데이터 중복 및 유실 없이 완벽하게 복구할 수 없다
**장애 복구 과정**
1. 재해 복구 계획
   - 복구 시간 목표(Recovery Time Objective, RTO)와 복구 지점 목표(Recovery Point Objective, RPO)를 염두해야 한다
   - 낮은 RTO를 지향할 수록 수동 작업과 애플리케이션 재시작을 최소화 해야한다
2. 데이터 유실 및 불일치 해결
   - DR 클러스터가 주 클러스터에 비해 얼마나 뒤떨어져있는지 모니터링 해야 한다
   - 메시지의 유실이 최소화될 수 있도록 조치해야 한다
3. 장애 복구 이후 애플리케이션 시작 오프셋 설정
   - 다른 클러스터로 옮겨간 애플리케이션이 데이터를 다시 읽어오기 시작할 오프셋을 설정해줘야 한다
   - **자동 오프셋 지정**: 처음 부터 읽거나, 마지막부터 읽는다. 처음부터 읽으면 메시지가 중복될 수 있고, 마지막부터 읽으면 메시지가 유실될 수 있다
   - **오프셋 토픽 복제**: `__consumer_offsets` 토픽을 DR 클러스터에 미러링한다. 
	   - 주 클러스터와 DR 클러스터의 오프셋이 일치할 것이라는 보장이 없다. 토픽이 생성된 뒤 1주일 후부터 미러링을 시작하면 두 클러스터의 오프셋은 일치하지 않는다
	   - 프로듀서 재시도로 인해 오프셋이 서로 달라질 수 있다. A가 재시도로 4, 5번 오프셋에 중복저장 됐을 때 DR 클러스터가 둘 중 하나만 미러링하면 오프셋이 달라질 수 있다
	   - 현재 미러링 솔루션이 트랜잭션을 지원하지 않는다. 카프카 컨슈머가 커밋한 오프셋이 해당 오프셋의 레코드보다 먼저 도착하여, 오프셋은 있지만 레코드는 없는 상황이 있을 수 있다.
  - **시간 기반 장애 복구**: 정확한 시점을 정해 복수할 수 있다. 직접 애플리케이션 로직을 작성하거나 `kafka-consumer-groups`를 사용한다
```sh
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --reset-offsets --all-topics --group my-group --to-datetime 2024-01-01T12:00:00.000 --execute
```
  - **오프셋 변환**:  외부 데이터 저장소나 카프카 토픽을 통해 주 클러스터와 DR 클러스터의 오프셋 매핑을 저장한다
4. 장애 복구 후 조치
   - 장애가 생겼던 주 클러스터를 DR 클러스터로 전환한다
   - 어디서부터 미러링을 해야할 지를 결정해야 하고, 주 클러스터는 DR 클러스터가 가지고 있지 않는 데이터를 가지고 있을 . 수 있다는 것을 염두에 두어야 한다
   - 원래 있던 데이터와 오프셋을 모두 제거한 후 새로 미러링을 시작할 수도 있다
5. 클러스터 디스커버리
   - 장애 상황에서 애플리케이션이 장애 복구용 클러스터와 통신을 시작하는 방법을 알 수 있도록 해야한다
   - 가장 많이 사용하는 방법은 호스트 이름을 단순하게 정한뒤 DNS를 써서 클러스터와 통신하는 것이다
   - 장애가 발생한 경우, DNS 이름을 스탠바이 클러스터로 돌리면된다
## 5. 스트레치 클러스터
- 여러 데이터센터에 걸쳐서 하나의 카프카 클러스터를 형성하는 것이다
- 하나의 카프카 클러스터를 여러 데이터센터에 설치한다
**장점**
- 동기적인 복제를 통해 DR 클러스터가 항상 100% 주 클러스터와 동기화 되어 있다
**단점**
- 대응할 수 있는 장애의 종류에 한계가 있다
- 데이터센터 전체에 장애가 난 경우에는 대응할 수 있지만, 애플리케이션 혹은 카프카에 장애가 발생한 경우에는 대응할 수 없다