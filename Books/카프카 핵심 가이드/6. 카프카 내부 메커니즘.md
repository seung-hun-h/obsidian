# 1. 클러스터 멤버십
- 카프카는 현재 브로커의 목록을 유지하기 위해 주키퍼 사용
	- 브로커는 고유한 식별자를 가짐
	- 주키퍼에 Ephermeral 노드로 등록
	- `/brokers/id` 경로를 브로커가 구독
- 브로커 목록을 구독하고있는 카프카 컴포넌트들은 빠르게 브로커가 내려갔음을 알아차릴 수 있다

> [!info] Ephermeral 노드
> 주키퍼와 연결을 유지하는 동안만 존재하는 임시노드

# 2. 컨트롤러
- 컨트롤러는 일반적인 카프카 브로커의 기능 + **파티션 리더를 선출**하는 기능을 가진다
- 가장 먼저 시작되는 브로커가 주키퍼의 `/controller` 에 Ephermeral 노드를 생성하여 컨트롤러가된다

**에포크(세대)**
- 브로커는 새로운 컨트롤러가 선출될 때마다 증가된 에포크를 전달 받는다
	- 더 낮은 에포크를 가진 컨트롤러에게 메시지를 받으면 무시한다
- 새로운 컨트롤러가 선출된 사실을 모르는 오래된 컨트롤러(좀비 컨트롤러)의 메시지를 무시할 수 있다
	- 서로 다른 두 브로커가 자신이 컨트롤러라고 생각하는 것을 **스플릿 브레인**이라 한다

**파티션 리더 선출 과정**
1. 컨트롤러가 브로커가 내려간 것을 알아차린다
2. 브로커가 리더를 맡고 있던 파티션을 순회하며 새로운 브로커를 할당해준다
3. 새로운 상태를 주키퍼에 쓴다
4. 모든 브로커에 `LeaderAndISR` 요청을 보내, 새로운 리더와 팔로워 정보를 전달한다
5. 새로 리더가된 브로커는 읽기 혹인 쓰기 요청을 처리한다. 팔로워는 새 리더의 정보를 복제한다
6. 컨트롤러는 모든 브로커에 `UpdateMetadata` 요청을 보내 `MetadataCache`를 최신화 하도록 요청한다 

## 1. KRaft: 카프카의 새로운 래프트 기반 컨트롤러

**컨트롤러를 변경한 이유**
- 브로커-주키퍼간 동기, 비동기 요청으로 인해 메타데이터 불일치가 발생할 수 있다
- 컨트롤러가 재시작될 때 주키퍼에게 모든 브로커와 파티션에 대한 메타데이터를 읽고, 그 메타데이터를 전송하는데 지연이 발생한다
- 메타데이터 소유권 관련된 아키텍처가 좋지 않다. 컨트롤러와 주키퍼에 분산되어 있다
- 주키퍼 자체로 분산시스템이라 두 개의 분산 시스템에 대해 배워야한다

**KRaft**
- 새로운 컨트롤러 설계의 핵심은 카프카 그 자체에 사용자가 상태를 이벤트 스트림으로 나타낼 수 있도록 하는 **로그 기반 아키텍처**를 도입한다는 점
	- 로그는 이벤트의 순서를 부여하여 컨슈머들이 항상 하나의 타임라인에 따라 움직이도록 보장한다
- 컨트롤러 노드들은  외부 시스템에 의존하지 않고 자체적으로 리더를 선출할 수 있다
- 메타데이터 로그의 리더 역할을 맡고 있는 컨트롤러를 **액티브 컨트롤러**라고 한다
	- 팔로워는 리더의 데이터를 복제하여 기나긴 리로드 시간을 필요로 하지 않는다

**쿼럼**
- 브로커 프로세스는 시작시 컨트롤러 쿼럼에 등록한다
	- 운영자가 등록을 해제하지 않는한 유지한다
- 온라인 상태지만 최신 메타데이터로 최신 상태를 유지하지 않은 브로커의 경우 **펜스된 상태**가 되어 클라이언트를 처리할 수 없다
# 3. 복제
- 복제가 중요한 이유는 개별적인 노드에 필연적으로 장애가 발생할 수 밖에 없는 상황에서 카프카가 **신뢰성**과 **지속성**을 보장하는 방식이기 때문이다

**리더 레플리카**
- 각 파티션의 리더 역할을 하는 레플리카
- 모든 쓰기 요청은 리더 레플리카에게 주어진다

**팔로워 레플리카**
- 파티션에 속한 모든 레플리카 중 리더 레플리카를 제외한 나머지
- 별도의 설정을 하지 않는 한, 클라이언트의 요청을 처리할 수 없다
- 리더의 데이터를 복제하여 최신 상태를 유지한다
- 리더 레플리카가 크래쉬난 경우 팔로워 중 하나가 리더가된다

**동기화**
- 리더 레플리카는 팔로워 레플리카가 최신 상태를 유지하는지 확인한다
	- 팔로워가 리더에게 읽기 요청을 보내면, 리더는 메시지와 함께 다음에 요청해야 할 메시지 오프셋을 전달한다
	- 각 팔로워가 마지막으로 요청한 오프셋을 확인하여 각 팔로워가 얼마나 뒤쳐졌는지 확인한다
- 지속적으로 최산 메시지를 요청하는 레플리카는 **인-싱크 레플리카**라고 부른다

**선호 리더**
- 선호 리더는 토픽이 처음 생성됐을 때 리더였던 레플리카를 말한다
- 선호 리더가 실제 리더인 경우 부하가 균등하게 분산된다
- `auto.leader.rebalance.enable=true`로 설정하면 선호 리더가 현재 리더가 아니지만 최신 상태인 경우 리더 선출을 실행한다
# 4. 요청 처리
**표준 헤더**
- 모든 메시지는 아래 표준 헤더를 가진다
	- 요청 유형: API키 라고도 부른다
	- 요청 버전: 서로 다른 버전의 클라이언트의 요청에 버전을 맞춰 응답을 할 수 있다
	- Correlation ID: 각각 요청에 붙는 고유 식별자
	- 클라이언트 ID: 요청을 보낸 애플리케이션을 식별

**카프카 내부 요청 처리**
1. 브로커는 연결을 받는 각 포트 별로 **억셉터 스레드**를 하나씩 실행시킨다
2. 억셉터 스레드는 들어온 요청을 **프로세서 스레드(네트워크 스레드)** 에 전달한다
3. 네트워크 스레드는 요청을 큐에 담는다
4. **IO 스레드**는 요청 큐에서 요청을 가져와 작업을 수행한 후 응답 큐에 담는다
5. 네트워크 스레드 응답 큐에서 응답을 가져와 클라이언트에게 전달한다

**클라이언트의 메타데이터 요청**
- 클라이언트는 브로커에 메타데이터를 요청한다
	- 토픽, 파티션, 레플리카에 대한 정보를 담고있다
- 클라이언트는 메타데이터를 캐시해 두었다가, 각 파티션의 리더 역할을 맡고있는 브로커에 바로 쓰거나 읽는다
- `metadata.max.age.ms` 설정이나 **Not a Leader** 에러 응답을 받은 경우 메타데이터를 새로고침한다
## 1. 쓰기 요청
- 브로커가 파티션에 쓰기 요청을 받은 경우 확인 사항
	- 사용자가 토픽에 쓰기 권한을 가지고 있는가?
	- 요청에 지정되어있는 acks의 값이 유효한가?
	- acks=all인 경우 메시지를 안전하게 쓸 만큼 충분한 인-싱크 레플리카가 존재하는가?
- 모든 사항을 확인후 브로커는 새 메시지를 디스크에 쓴다

## 2. 읽기 요청
- 클라이언트는 브로커에 토픽, 파티션, 오프셋 정보를 전달해 메시지를 보내달라는 요청을 한다
- 브로커가 리턴할 수 있는 데이터 양의 상한과 하한을 설정할 수 있다
- 카프카는 클라이언트에 전달할 메시지에 **제로 카피 최적화**를 적용했다
	- 메시지를 중간 버퍼를 거치지 않고 바로 네트워크로 전달한다
- 클라이언트는 **모든 인-싱크 레플리카에 쓰여진 메시지만 읽을 수 있다**
- 컨슈머가 매우 많은 수의 파티션으로부터 이벤트를 읽어 오는 경우 오버헤드를 최소화하기 위해 **읽기 세션 캐시**를 사용한다
	- 세션이 한 번 생성되면 컨슈머들은 더 이상 요청을 보낼 때마다 파티션을 지정할 필요 없이 점진적으로 읽기 요청을 수행할 수 있다
	- 브로커는 변경이 있는 경우에만 응답에 변경 사항을 함께 보내면된다
## 3. 기타 요청
- 카프카 프로토콜은 여러가지 서로 다른 요청 유형을 정의하고 있고 계속 늘어난다
- 개발자들은 새로운 프로토콜을 추가하거나 기존의 프로토콜을 발전시킨다
- 브로커들은 이전 버전의 메시지를 처리할 수 있으므로, 클라이언트 버전을 올리기전에 브로커 버전을 올려야 한다
# 5. 물리적 저장소
- 파티션은 서로 다른 브로커로 분리될 수 없고, 서로 다른 디스크에 분할 저장될 수 없다
	- 여러 디스크에서 읽는 경우 지연이나 트랜잭션 처리가 힘들어질 수 있다
## 1. 계층화된 저장소
- 대량의 데이터를 저장하기 위해 사용한다
	- 기본 버전에는 탑재되지 않고 컨플루언스와 같은 상용버전을 사용해야 한다
- 데이터의 접근 빈도와 중요도에 따라 데이터를 저장하는 위치를 구분한다
- 카프카 클러스터의 메모리와 CPU에 구애받지 않고 저장소를 확장할 수 있다

**로컬 저장소**
- 로컬 세그먼트를 저장하기 위해 카프카 브로커의 로컬 디스크를 사용한다
- 원격 저장소에 비해 지연이 훨씬 짧다

**원격 저장소**
- 완료된 세그먼트를 저장하기 위해 HDFS 혹은 S3를 사용한다
- 원격 저장소에 위치한 세그먼트는 브로커로 복원될 필요 없이 바로 클라이언트로 전달된다

## 2. 파티션 할당
- 사용자가 토픽을 생성하면, 카프카는 파티션을 브로커 중 하나에 할당한다
- 할당된  파티션은 브로커의 각 디렉토리 중 파티션의 개수가 가장 적은 디렉토리에 저장된다

**파티션 할당의 목표**
- 레플리카를 최대한 브로커간 고르게 분산시킨다
- 각 파티션에 대해 각각의 레플리카는 서로 다른 브로커에 배치한다
- 브로커에 랙 정보가 설정되어 있다면, 가능한 한 각 파티션의 레플리카들을 서로 다른랙에 위치시킨다
## 3. 파일 관리
- 사용자는 토픽에 대한 보존 기한을 설정할 수 있다
	- 오래되거나 크기가 큰 데이터를 지운다
- 큰 파일에서 삭제해야 할 메시지를 찾는 것은 오래 걸리므로, 파티션을 여러 세그먼트로 나눠서 메시지를 저장한다
- 세그먼트를 열어서 메시지를 작성하고, 한도가 가득찬 경우 세그먼트를 닫고 새로운 세크먼트를 생성한다
- 쓰여지고 있는 세그먼트를 **액티브 세그먼트**라고 한다. 액티브 세그먼트는 어떠한 경우에도 삭제되지 않는다

## 4. 파일 형식
- 프로듀서-브로커간 데이터의 형식, 브로커가 저장하는 데이터의 형식, 브로커-컨슈머간 데이터 형식 모두 **같다**
	- 형식을 모두 맞춰서 제로 카피 최적화를 할 수 있다
	- 압축한 데이터를 다시 풀지 않고, 그대로 저장하고 다시 전달할 수 있다
- 카프카 브로커는 서로 다른 파일 형식이 섞여 있는 파일의 처리 방법을 알아야 한다
	- 카프카는 카프카 메시지의 **시스템 헤더**를 읽어 형식을 식별하고 각각의 형식에 맞게 메시지를 처리한다

## 5. 인덱스
- 카프카는 오프셋과 세그먼트 파일 및 그 위치를 매핑하는 인덱스를 가진다
- 카프카는 타임스탬프와 메시지 오프셋을 매핑하는 또다른 인덱스를 가진다
	- 카프카 스트림즈 같은 경우 타임 스탬프를 기준으로 메시지를 광범위 하게 검색하고 몇몇 장애 복구 상황에서도 유용하게 사용할 수 있다
## 6. 압착
- 카프카는 **삭제, 압착** 두 가지 보존 정책을 지원한다
	- 지나치게 커지는 토픽을 방지, 일정 기한이 지난 레코드 삭제
## 7. 압착의 작동 원리
- 파티션은 **클린, 더티** 영역으로 나뉜다
	- 클린: 압착이 일어난 영역
	- 더티: 압착이 일어나지 않은 영역
1. 브로커는 압착 매니저 스레드와 압착 스레드를 실행해, 더티 메시지의 비율이 가장 높은 파티션을 골라 압착하여 클린 상태로 만든다
2. 더티 영역을 읽어 메시지 키(16비트)-메시지 오프셋(8비트)로 이뤄진 **압착맵**을 만들어 사용해, 적은 메모리를 사용해 압착한다
3. 클린 영역을 읽어 압착 맵과 비교한다. 
	1. 맵에 존재하지 않는 경우, 여전히 최신 값이므로 교체용 세그먼트에 복사한다
	2. 맵에 존재하지 않는 경우, 다른 최신 값이 있으므로 넘어간다
4. 최신 값을 가진 세그먼트가 모두 복제되면 교체용 세그먼트와 원본 세그먼트를 바꾼다
5. 작업이 완료되면 키별로 하나의 메시지만 남는다
## 8. 삭제된 이벤트
- **특정 키에 null 값을 갖는 메시지(툼스톤 메시지)** 를 쓰면 가장 최근 메시지조차도 남지 않고 시스템에서 제거된다
	- 카프카는 사전에 설정된 시간만큼 이 메시지를 유지한다
## 9. 토픽은 언제 압착되는가?
- 액티브 세그먼트는 절대  압착되지 않는다
- 토픽의 내용물이 50% 이상이 더티 레코드인 경우 압착을 시작한다
- 두 설정 매개변수를 사용해 조절할 수 있다
	- `min.compaction.lag.ms`
		- 메시지가 쓰여진 뒤 압착 될때까지 지나야 하는 최소 시간
	- `max.compaction.lag.ms`
		- 메시지가 쓰여진 뒤 압착이 가능해질 떄까지 딜레이될 수 있는 최대 시간. 특정 기한 안에 반드시 압착이 실행되어야 하는 것을 보장해야할 때 사용한다