# 1. 신뢰성 보장
- **신뢰성**
	- 시스템이 예상한대로 데이터를 처리하고, 전달하며, 실패 시에도 복구할 수 있는 상태를 유지하는 능력을 말한다
- **보장**
	- 서로다른 상황에서도 시스템이 지킬 것이라 보장되는 행동을 말한다
- **카프카의 보장**
	- 파티션 안의 메시지들간 순서를 보장한다
	- 클라이언트가 쓴 메시지는 모든 인-싱크 레플리카의 파티션에 쓰여진 뒤에야 '커밋'된 것으로 간주된다
	- 커밋된 메시지들은 최소 1개의 작동 가능한 레플리카가 남아있는한 유실되지 않는다
	- 컨슈머는 커밋된 메시지만 읽을 수 있다
- 카프카가 보장하는 것 자체로는 신뢰성있는 시스템을 만들 수 없다
	- 신뢰성 있는 시스템을 구축하는데는 트레이드  오프가 존재한다
	- 카프카의 매개변수를 조절하므로써 트레이드 오프를 조절할 수 있다
# 2. 복제
- 카프카의 복제 매커니즘은 카프카 신뢰성 보장의 핵심적인 특징이다
- **카프카 복제 매커니즘의 특징**
	- 각 파티션의 데이터는 순서가 보장된다
	- 각 파티션은 다수의 레플리카를 가질 수 있다
	- 모든 이벤트는 리더 레플리카에 쓰여지고, 팔로워는 리더의 이벤트를 복사한다
	- 리더가 작동 불능이되면 인-싱크 레플리카 중 하나가 새로운 리더가 된다
- **인-싱크 레플리카의 조건**
	- 주키퍼와의 활성 세션이 있다. 설정된 시간 내 주키퍼에게 하트비트를 전송했다
	- 설정된 시간 사이에 리더로부터 최신 메시지를 받아와야 한다
- 동기화가 느린 인-싱크 레플리카는 종단 지연을 발생시킬 수 있다
# 3. 브로커 설정
## 1. 복제 팩터
- 복제 팩터 설정
	- `replication.factor `: 토픽 단위의 복제 팩터 설정
	- `default.replication.factor`: 자동으로 생성되는 토픽에 적용되는 복제  팩터 설정
- 복제 팩터의 크기는 가용성과 하드웨어 사용량 사이의 트레이드 오프다
	- 복제 팩터가 N이면 N-1개의 브로커가 중단되더라도 토픽의 데이터를 읽고 쓸 수 있다
	- 복제 팩터가 N이면 N개의 브로커, N배의 디스크 공간이 필요하다
- 토픽의 복제 팩터를 설정할 때는 **가용성**, **지속성**, **처리량**, **종단 지연**, **비용**을 고려 해야한다
- 랙단위 사고를 방지하기 위해서는 브로커를 서로 다른 랙에 배치한뒤 `brocker.rack` 설정을 잡아준다. 클라우드 환경에서 운용중인 경우, 가용 영역을 랙과 비슷한 개념으로 사용한다
## 2. 언클린 리더 선출
- **언클린 리더 선출** (`unclean.leader.election`): 인-싱크 레플리카 중 리더를 선출할 수 없을 때 아웃-오브-싱크 레플리카에서 리더를 선출하는 것을 말하며, 이 경우 데이터 유실 및 일관성 문제가 발생할 수 있다
## 3. 최소 인-싱크 레플리카
- `min.insync.replicas`: 최소한 몇 개의 레플리카가 메시지를 유지해야 하는지를 설정하여 데이터의 안전성을 보장한다. 설정된 값보다 적은 레플리카만 사용할 수 있을 경우, 프로듀서는 데이터를 전송할 수 없다(`NotEnoughReplicasException`)
## 4. 레플리카를 인-싱크 레플리카 상태로 유지하기
- **아웃-오브-싱크 레플리카 조건**: 레플리카가 주키퍼와의 연결이 끊기거나, 리더의 최신 메시지를 일정 시간 내에 따라잡지 못하면 아웃-오브-싱크 상태로 전환된다
- `zookeeper.session.timeout.ms`
	- 주키퍼와의 세션 유지 시간을 설정하여, 이 시간이 지나면 레플리카는 아웃-오브-싱크 상태로 전환된다. 가비지 컬렉션이나 네트워크 지연 등으로 인해 무작위적인 변동이 발생하지 않도록 충분히 크게 설정해야 한다
- `replica.lag.time.max.ms`
	- 레플리카가 리더로부터 데이터를 받아오지 못하는 최대 시간을 설정한다. 이 시간이 지나면 레플리카는 인-싱크 상태에서 제외된다
## 5. 디스크에 저장하기
- `flush.messages`
	-  디스크에 저장되지 않는 최대 메시지 수
- `flush.ms`
	- 얼마나 자주 디스크에 저장하는지 설정
- 위 설정을 통해 얼마나 자주 `fsync`가 발생할 지 조절할 수 있다
	- 강제로 데이터를 디스크에 쓰는 명령어
	- 카프카는 기본적으로 비활성화
	- `acks`, `min.insync.replicas`로 성능과 데이터 영속성에 균형을 잡는다
# 4. 신뢰성 있는 시스템에서 프로듀서 사용하기
- 높은 신뢰성 설정을 브로커에 적용하더라도, 프로듀서 역시 신뢰성있도록 설정해주지 않는다면 시스템 전체로서는 여전히 데이터가 유실될 수 있다
- 신뢰성 요구 조건에 맞도록 `acks` 를 설정해야 한다
- 설정과 코드 모두에서 에러를 올바르게 처리해야 한다
## 1. 응답 보내기
- `acks=0`
	- 프로듀서가 네트워크로 메시지를 전송한 시점에 메시지가 카프카에 성공적으로 쓰여진 것으로 간주
	- 지연은 낮지만, 종단 지연이 개선되진 않는다
- `acks=1`
	- 리더가 메시지를 받아서 파티션에 쓴 후 응답 또는 에러를 보낸다
	- 팔로워로 데이터가 복제되기 전 리더에 장애가 발생하면 데이터가 유실될 수 있다
- `acks=all`
	- 모든 인-싱크 레플리카가 메시지를 받아갈 때 까지 기다렸다가 응답이나 에러를 보낸다
	- 프로듀서는 메시지가 완전히 커밋될 때까지 계속해서 메시지를 재전송한다
	- 프로듀서의 지연이 길어질 수 있다
## 2. 프로듀서 재시도 설정하기
- 프로듀서가 자동으로 처리하는 에러
	- `LEADER_NOT_AVAILABLE`과 같이 재시도 한다면 성공할 수 있는 에러
- 개발자들이 직접 처리해야하는 에러
	- `INVALID_CONFIG`와 같이 재시도 해도 성공할 수 없는 에러
- 메시지가 유실되지 않는 것이 목표
	- 재시도 가능한 에러가 발생한 경우, 프로듀서가 계속해서 메시지 재전송을 시도하도록 설정
	- 재시도는 결과적으로 메시지가 중복될 위험을 내포한다
## 3. 추가적인 에러 처리
- 프로듀서가 재시도할 수 없는 에러
	- 메시지 크기에 관련되어 있거나 인가 관련에러
	- 메시지가 브로커에 전송되기 전에 발생한 에러(직렬화 관련한 에러)
	- 모든 재시도 횟수 소진 및 재시도 과정에서 프로듀서의 가용 메모리가 가득찬 경우
	- 타임아웃
- 위 같은 에러를 처리하는 방식은 아키텍처와 요구 사항에 따라 달라진다
# 5. 신뢰성 있는 시스템에서 컨슈머 사용하기
- 컨슈머는 커밋된 데이터만 읽을 수 있다
- 컨슈머는 어느 메시지를 어디까지 읽었는지 추적하여, 메시지가 누락되지 않도록 해야한다
- 컨슈머는 메시지를 배치로 읽어온 뒤, 배치별로 마지막 오프셋을 확인하고, 브로커에게 받은 마지막 오프셋 값에서 시작하는 다른 메시지 배치를 요청한다
- 한 컨슈머가 정지한 경우 다른 컨슈머가 작업할 수 있게 하기 위해 오프셋을 커밋한다
	- '다른 컨슈머'는 이전 컨슈머와 완전히 다른 컨슈머일 수도 있고, 그 컨슈머가 재시작한 것일 수 있다
## 1. 신뢰성 있는 처리를 위해 중요한 컨슈머 설정
- `group.id`
	- 같은 값을 가진 경우 두 컨슈머는 서로 다른 부분의 메시지를 읽는다
	- 다른 값을 가진 경우 컨슈머가 구독한 토픽의 모든 메시지를 읽을 수 있다
- `auto.offset.reset`
	- 커밋된 오프셋이 없을 때, 컨슈머가 브로커에 없는 오프셋을 요청할 때 컨슈머가 어떻게 행동할 지 결정한다
- `enable.auto.commit`
	- 일정한 시간에 맞춰 컨슈머가 자동으로 오프셋을 커밋할 것인지, 코드에서 직접 오프셋을 커밋할 것인지 결정한다
- `auto.commit.interval.ms`
	- 자동으로 오프셋을 커밋할 경우, 얼마나 자주 커밋할 것인지 결정한다
## 2. 컨슈머에서 명시적으로 오프셋 커밋하기
##### 1. 메시지 처리 후, 오프셋 커밋
- 메시지를 읽고 처리한 후에 오프셋을 **명시적으로 커밋**해야 한다. 이를 통해 메시지가 성공적으로 처리된 후에만 커밋이 이루어지도록 보장할 수 있다
	- **자동 오프셋 커밋**: 설정에 따라 자동으로 오프셋을 커밋할 수 있지만, 정확한 타이밍에 커밋하는 것을 보장하지 못할 수 있어 데이터 누락이나 중복 문제가 발생할 가능성이 있다
	- **폴링 루프 끝에서 커밋**: 메시지를 처리한 뒤, 주기적으로 오프셋을 커밋하는 방법이다.
	- **복잡성 증가**: 스레드가 여러 개이거나 상태를 유지해야 하는 처리를 할 때는 관리가 더 복잡해진다
##### 2. 커밋 빈도와 성능 사이의 트레이드오프
- 커밋은 상당한 오버헤드를 수반한다
- 커밋의 주기는 성능과 중복 발생 요구 조건 사이에서 균형을 맞춰야 한다
##### 3. 정확한 시점에 정확한 오프셋 커밋
- 언제나 **처리가 완료된 메시지의 오프셋을 커밋**하는 것이 중요하다
##### 4. 리밸런스
- 애플리케이션을 개발할 때는 컨슈머가 리밸런스가 발생할 것이라는 점을 인지해야 한다
- 할당된 파티션이 해제되기 전에 오프셋을 커밋하고, 새로운 파티션이 할당되었을 때 애플리케이션이 보유하고 있던 상태를 삭제해주는 작업 등을 해야 한다
##### 5. 컨슈머는 재시도 해야할 수도 있다
- 재시도 가능한 에러가 발생 했을 경우 사용 가능한 방법
	1. 마지막으로 처리에 성공한 레코드 오프셋 커밋 -> 나중에 처리해야 할 레코드 버퍼에 저장 -> `pause()` 호출 -> 레코드 처리
	2. 별도의 토픽에 쓴 뒤 계속 진행.
##### 6. 컨슈머가 상태를 유지해야 할 수도 있다
- 이동평균을 구해야 하는 등 상태를 유지해야 할 수도 있다
- 마지막으로 누적된 값을 애플리케이션이 오프셋을 커밋할 때 `results` 토픽에 쓴다
	- 스레드가 시작될 떄 작업이 중단된 시점과 마지막으로 누적된 값을 가져올 수 있다
# 6. 시스템 신뢰성 검증하기
## 1. 설정 검증하기
- 설정 검증은 **카프카 클러스터가 요구 조건을 충족하고 예상대로 동작하는지**를 확인하는 데 도움을 준다. 이를 통해 시스템이 신뢰성을 유지할 수 있는지 확인할 수 있다
- **설정 검증의 목적**:
	- **요구 조건 충족 확인**: 클러스터의 설정이 요구사항을 만족하는지 검증한다
	- **시스템의 예상 작동 추론**: 시스템이 예상대로 작동할지를 미리 확인한다. 이를 위해 `VerifiableProducer`와 `VerifiableConsumer`를 활용할 수 있다
- **검증할 테스트 시나리오**:
	- **리더 선출 테스트**:  리더 교체 후 프로듀서와 컨슈머가 **얼마나 빨리 작업을 재개**할 수 있는지 확인한다
	- **컨트롤러 선출 테스트**: 컨트롤러가 다시 시작되면 **시스템이 정상적으로 재개**되는 데 걸리는 시간을 측정한다
	- **롤링 재시작 테스트**: 브로커를 하나씩 재시작하면서 **메시지가 유실되지 않는지** 확인한다
	- **언클린 리더 선출 테스트**: 아웃-오브-싱크 레플리카가 리더로 선출될 때 발생할 수 있는 **데이터 유실**을 확인한다
- **테스트 방법**:
	- 시나리오 하나를 선택한 뒤 **검증용 프로듀서와 컨슈머**를 실행시켜 테스트한다
## 2. 애플리케이션 검증하기
- 애플리케이션 수준에서 신뢰성을 보장하려면, 다양한 장애 상황을 대비하여 검증하는 것이 중요하다
- **애플리케이션 검증의 주요 항목**:
    - **에러 처리**: 예상하지 못한 에러를 처리할 수 있는 **커스텀 에러 처리**가 설정되어 있는지 확인한다
    - **오프셋 커밋**: 컨슈머가 올바르게 오프셋을 커밋하는지 점검한다
    - **리밸런스 리스너**: 리밸런스 상황에서 컨슈머의 상태를 적절하게 관리할 수 있는지 확인한다
- **검증할 장애 상황**:
	- **브로커 연결 끊김**: 클라이언트가 브로커 중 하나와의 연결이 끊겼을 때 애플리케이션이 잘 대응하는지 확인한다
	- **네트워크 지연**: 브로커와의 통신에 **긴 지연**이 있을 경우에도 시스템이 정상적으로 작동하는지 테스트한다
	- **디스크 문제**: 디스크가 **꽉 차거나 멈춘 경우**에도 데이터가 손실되지 않고 애플리케이션이 적절히 대처할 수 있는지 확인한다
	- **롤링 재시작 테스트**: 브로커, 프로듀서, 컨슈머를 각각 하나씩 재시작하면서 **데이터 유실이나 장애** 없이 정상적으로 동작하는지 테스트한다
- **툴 활용**:
	- 다양한 테스트 시나리오를 위해 **트록도르**와 같은 툴을 사용해볼 수 있다. 이는 장애 시나리오를 시뮬레이션하는 데 도움이 된다.
## 3. 프로덕션 환경에서 신뢰성 모터니터링 하기
 - 프로덕션 환경에서는 시스템이 신뢰성을 유지하고 있는지를 **지표와 모니터링 도구**를 통해 지속적으로 확인해야 한다
- **프로듀서 모니터링**:
    - **레코드별 에러율**: 메시지를 전송할 때 발생하는 에러의 비율입니다. 에러율이 높다면 시스템에 문제가 있는 것이다
    - **재시도율**: 메시지가 제대로 전송되지 않아 재시도한 비율입니다. 재시도율이 높다면 **네트워크 문제**나 **브로커 문제**가 있을 수 있다
- **컨슈머 모니터링**:
    - **컨슈머 랙**: 컨슈머가 데이터를 읽는 속도가 프로듀서가 데이터를 쓰는 속도보다 느릴 때 발생하는 지연을 **컨슈머 랙**이라고 한다. 이를 줄이는 것이 중요합니다
    - **버로우(Burrow)**: 컨슈머 랙을 모니터링하고, 컨슈머 그룹이 정상 작동하는지 확인하기 위해 **Burrow**와 같은 도구를 사용하면 좋다
- **데이터 흐름 모니터링**:
    - **카프카 브로커 에러 지표**: 카프카 브로커는 클라이언트로 보내는 **에러 응답률**을 보여주는 지표를 제공한다
        - **FailedProduceRequestsPerSec**와 **FailedFetchRequestsPerSec** 같은 지표를 모니터링하면 브로커가 정상적으로 작동하는지 확인할 수 있다
        - 요청 실패가 알 수 없는 이유로 증가하는 경우, 반드시 원인을 파악하고 대응해야 한다