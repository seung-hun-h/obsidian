## 1. 정의
텍스트, 이미지, 사용자 등 추상적이고 비정형적인 데이터를 숫자로 이루어진 벡터로 바꾸는 것이다. 특히 텍스트에서의 임베딩은 **문장을 벡터로 바꿔서 컴퓨터가 처리할 수 있도록 만드는 과정이다**.

```
"안녕하세요" → [0.12, 0.87, ..., -0.03]
```

> [!info] 벡터(Vector)
> 벡터랑 여러개의 숫자로 이루어진 배열이다.
> 예를들어, [0.4, 1.2, -3.0, 5]는 4차원 벡터이다
> 수학적으로는 방향성과 크기를 가진 점이고, 머신러닝에서는 벡터를 **특징의 모음**이라고 보면된다

## 2. 임베딩 벡터
임베딩 벡터는 문장, 단어, 이미지등 비정형 데이터를 컴퓨터가 이해할 수 있도록 수치로 바꾼 것이다. 즉, 임베딩의 결과로 임베딩 벡터가 생성된다.

임베딩 벡터는 아래와 같이 활용된다
- 유사 문장 검색: 새로운 문장과 기존 문장의 벡터를 비교해 가장 비슷한 문장  찾기
- 클러스터링: 임베딩된 벡터끼리 군집화([[KMeans]])
- 추천 시스템: 유사도 기반으로 콘텐츠 추천
- 시각화: 고처원 벡터 -> 2D로 줄여서 시각적으로 분포 확인(PCA, t-SNE 등)
## 3. 임베딩 방식
### 임베딩 방식

| 방식           | 설명          | 특징                    |
| ------------ | ----------- | --------------------- |
| [[TF-IDF]]   | 단어 빈도 기반    | 빠르고 단순, 의미보단 단어 겹침 중심 |
| [[Word2Vec]] | 단어 의미 벡터    | 문맥 기반 단어 임베딩          |
| [[FastText]] | 철자 단위까지 고려  | 오탈자, 신조어에 강함          |
| BERT/SBERT   | 문장 전체 의미 반영 | 문맥 고려, 문장 단위 임베딩 가능   |
### 문장 단위 임베딩
**Word2Vec**는 단어 단위의 임베딩 방식이다. 하지만 단어는 여러 문맥에서 다른 의미를 나타내는 경우가 많다. 따라서 전체 문장을 벡터로 표현해야 할 경우가 많은데 이를 위해서 나타난 것이 **문장 임베딩**이다. 대표적인 문장 임베딩 방식으로 **[[SBERT | SBERT(Sentence-BERT)]]** 가 있다. SBERT는 문장 의미 중심으로 임베딩, [[코사인 유사도]] 로 문장 간 의미 비교 가능, 한국어 지원 등의 특징이 있다.


