## 1. 정의
대규모 말뭉치로부터 단어의 문맥 기반 의미를 학습해 고정된 벡터로 표현하는 알고리즘이다. **Skip-gram** 혹은 CBOW 구조를 사용하여 주변 단어 **예측**을 통해 벡터를 학습하며, 결과적으로 비슷한 문맥에서 쓰이는 단어들은 벡터 공간상 가깝게 배치된다

- **예측 기반 임베딩**
	- 주변 단어와의 **동시 등장 관계(co-occurrence**를 보고 주변 단어를 예측하거나 중심 단어를 예측하는 방식으로 학습한다. 반면 [[TF-IDF]]는 빈도 기반이다.
- **정적인 단어 벡터**
	- 단어 하나당 벡터 하나만 학습한다. 즉, '은행'은 문맥에 상관없이 항상 같은 벡터이다
- **형태소와 문자 정보를 반영하지 않는다**
	- 단어 전체를 하나로 본다. '학교'와 '학교에'는 서로 다른 단어로 본다

## 2. 예시
```text
"나는 커피를 마신다."  
"나는 차를 마신다."
```
두 문장은 다르지만 의미하는 바가 비슷하다. '커피'와 '차'는 비슷한 문맥에서 자주 등장하는데, Word2Vec은 이러한 문맥을 학습하여 두 문장을 비슷한 벡터 공간에 배치한다.

## 3. 학습방식
### 1. CBOW와 Skip-gram

| 항목    | CBOW (Continuous Bag of Words) | Skip-gram           |
| ----- | ------------------------------ | ------------------- |
| 학습 목표 | **주변 단어들로 중심 단어 예측**           | **중심 단어로 주변 단어 예측** |
| 학습 방향 | context -> target              | target -> context   |
CBOW는 문맥을 입력해 단어를 예측하고, Skip-gram은 단어를 입력해 문맥을 예측한다.
### 2. 학습 결과 비교

| 비교 항목           | CBOW       | Skip-gram  |
| --------------- | ---------- | ---------- |
| **훈련 속도**       | 빠름 (벡터 평균) | 느림 (다수 예측) |
| **희귀 단어 처리**    | 약함         | 강함 ✅       |
| **많은 데이터에 유리**  | 예          | 예          |
| **적은 데이터에 유리**  | ❌          | ✅ 더 잘 학습함  |
| **일반적인 의미 유사성** | 양호         | 매우 강함 ✅    |
| **복잡한 문맥 이해**   | 약함         | 좋음 ✅       |
CBOW는 빠르고 일반적인 의미 벡터를 학습하는데 적합하고, Skip-gram은 단어 의미의 미세한 차이까지 반영하는 정밀한 벡터를 학습하는데 유용하다.

## 4. 단어 연산
```python
import gensim.downloader as api

# 1. 사전 학습된 Word2Vec 모델 로딩 (구글 뉴스 3백만 단어)
model = api.load("word2vec-google-news-300")  # 약 1.5GB 다운로드됨

# 2. 벡터 연산: king - man + woman ≈ queen
result = model.most_similar(positive=["king", "woman"], negative=["man"], topn=5)

# 3. 결과 출력
for word, score in result:
    print(f"{word}: {score:.4f}")

```

```text
queen: 0.7118
monarch: 0.6183
princess: 0.5815
empress: 0.5432
duchess: 0.5312
```

Word2Vec는 단어의 관계를 벡터 차원 안에 반영되도록 학습되어있다. 즉, **비숫한 문맥에 자주 등장한 단어일수록 벡터 공간상에서 서로 가까운 위치**에 존재한다. 따라서 벡터는 단순한 숫자 모음이 아닌 **의미의 방향성** 과 **의미의 차이**를 가진다.

```
      ↑ y축
      |
   6  |                      ● queen (5,6)   
   5  |  ● woman (2,5)            
   4  |                      ● king (5,4)     
   3  |  ● man (2,3)
      |
      └────────────────────────────→ x축
         0   1   2   3   4   5
```
아래와 같이 연산이 가능해진다.
- `king(5, 4) - man(2, 3) + woman(2, 5) = queen(5, 6)`

