## 1. 버전 선택
- major.minor.patch
- major, minor 릴리즈는 새로운 기능이 들어가서 문제가 발생할 수 있음
- patch(maintenance) 릴리즈는 버그 수정 등만 반영됨
- 최신의 maintenance 릴리즈를 사용하는 것이 좋다

**예시**
- 최신 버전이 3.3.0 이니까 클라이언트도 3.3.0을 쓰자 (X)
- 최신 버전이 3.3.0 이니까 클라이언트는 3.2.1을 쓰자 (O)
- 최신 버전이 3.3.1 이니까 브로커는 3.2.1을 쓰고 클라이언트는 3.3.1을 쓰자 (O)
	- 브로커는 이전의 minor 버전을 사용하는 것 권장
## 2. 업그레이드 
- Client
	- 우선
	- 자주
- Broker
	- 나중
	- 이따금
	- 권장 버전
#### 배경
**Kafka Protocol**
- Broker-Client 간에 주고 받는 신호
- 버전 개념이 존재한다
- 양방향 호환성을 유지한다
	- 클라이언트는 특정한 요청을 보내기 전에 자기가 알아들을 수 있는 가장 최신 버전에 대한 정보를 보낸다
	- 브로커는 지원하지 않는 버전의 요청이 오면 처리를 거부
- 브로커를 먼저 업데이트를 해서 문제가 발생한 경우 브로커를 사용하는 모든 곳에 영향을 미친다
- 클라이언트를 먼저 업데이트하면 클라이언트를 사용하는 곳에만 문제가 발생한다

## 3. 토픽 이름 정하기
- `.`을 사용하지 않는다
	- 각종 모니터링 지표를 JMX를 통해서 노출한다. JMX는  `.`과  `_`을 구분하지 않는다
- `_`로 시작하지 않는다
	- 카프카 내부 톡픽이  `_`로 시작한다
	- 충돌날 수 있다
## 4. 파티션 수 정하기
#### 파티션의 의미
- 파팋션은 컨슈머가 순차적으로 읽어서 처리해야 할 레코드를 모아놓은것
- 컨슈머는 주어진 파티션을 순차적으로 읽는 것
	- Non thread safe
	- 스레드 별로 객체를 생성해서 사용할 것을 상정하고 만든 것
#### 흔하게 하는 실수
- 데이터가 많이 들어올테니까 미리 넉넉하게 잡는다 -> 효과 없음
	- 파티션은 파일 자원을 생각보다 많이 잡아먹는다
	- 단순히 파티션을 늘린다고 성능이 좋아지진 않는다
#### 파티션을 정하는 기준
- 레코드 정렬에 대한 요구 조건을 깨지 않도록 한다
	- 모든 레코드가 완전히 정렬되기 위해서는 파티션 1갱
- 컨슈머가 처리하기에 충분하도록 한다
	- 10개의 컨슈머가 필요하다면 파티션 수는 최소 10개로 한다
	- 모니터링을 통해 컨슈머의 개수와 파티션의 수를 조절한다
- 브로커간 부하가 균등하도록 한다(권장)
	- 브로커 6개, 파티션 5개, Replication Factor 3
		- 5 * 3 = 15개의 레플리카는 6개에 균등하게 배분되지 않음
	- 브로커 6개, 파티션 4개, Replication Factor 3
		- 4 * 3 = 12개의 레플리카는 6개에 균등하게 배분됨
- 2024년 5월 기준 표준 크기의 클러스터 크기는 브로커 5대
	- 처음에는 파티션의 수를 5개로 생성한 뒤 필요한만큼 늘려 나간다
##### Head of Line 문제
- 파티션에서 레코드를 순차적으로 읽어서 처리 중, 문제가 있는 레코드가 중간에 끼어있는 경우 전체 처리가 다 막힌다
- 처리 중에 문제가 발생할 수 있다는 것을 항상 염두하자
- 해결 방법
	- 문제가 발생한 레코드에 대해 로그를 남기고 계속 진행한다
	- Dead Letter Queue: 문제가 발생한 레코드만 모아두는 토픽을 뒀다가 나중에 한 번에 처리한다. 카프카 커넥트가 지원
##### Queue Semantic 문제
- 순차성을 엄격하기 지킬 필요 없이, 그저 쓰는 쪽과 읽는 쪽을 분리하고 싶은 경우
- 해결
	- Parallel Consumer를 사용한다.
		- 장점: 사용자가 원하는 수준의 순서 보장을 자유롭게 선택할 수 있다. 
			- Partition, Key, Unordered
		- 단점: 잘 사용하기 어렵다
	- Queues for Kafka
		- 순차성 제한이 없는 새로운 형태의 Consumer Group을 도입(Shared Group)
		- 2024년 12월 현재 Accepted
## 5. 컨슈머 그룹 정하기
- 컨슈머 그룹 = 논리적인 컨슈머
	- 여러 컨슈머가 서로 협조하여 파티션을 나눠서 읽을 수 있게함
- 구독(Subscribe) 작업에 대한 하나의 상태가 유지된다
	- 2개 이상의 작업 상태가 필요하면 배포된 구현체는 1개일지라도 Consumer Group은 2개 이상이어야 한다
	- `group.id`, `bootstrap.servers`, `topic`를 하드 코딩하지 마라
		- 장애 대응하기 어렵다
## 6. 컨슈머 설정 잡기
- 모르는 설정은 건드리지마라
- 재해 복구는 반드시 염두에 두어야 한다
#### 코드에 고정시키면 안 좋은것
- bootstrap.servers
- group.id
- auto.offset.reset
- 사용하는 topic
#### 코드에 고정시키면 좋은 것
- key.deserializer
- value.deserializer
- enable.auto.commit, auto.commit.interval.ms
#### 바꾸는게 좋은 것
- metadata.max.age.ms: 기본값 5분 -> 3분 많이 씀
#### 설정으로 빼 놓으면 좋은것
- partition.assignment.strategy
- group.instance.id
- session.timeout.ms
- max.poll.interval.ms
#### 나머지는 그냥 둬라
- max.poll.records
	- 대부분이 잘못 이해하고 있는 설정?
## 7. Kafka metadata
- 카프카 클러스터의 현재 상태
- 클러스터에 속한 브로커 목록과 그 현재 상태
	- 브로커 id, IP 주소
- 현재 생성되어있는 토픽 및 설정
	- 토픽이름, 파티션 수, 파티션 별 최신 오프셋
- 레플리카별 상태
	- 리더인지 팔로워인지
- **Kafka metadata는 사용자의 눈에 보이지 않는다**

## 8. Kafka metadata 동작 매커니즘: 브로커와 클라이언트 교환
#### bootstrapping
- 클라이언트가 처음으로 클러스터에 연결을 시도해서 첫 metadata를 받아오는 과정
- 브로커 중 아무거나 하나에만 연결이 성공하면 metadata를 요청해서 최신 metadata를 가져온다
	- 클라이언트의 bootstrap.servers
	- 브로커가 보내주는 응답 안에 전체 브로커 목록, 토픽 파티션 레플리카 목록이 전부 들어있다
	- 전체 브로커 중 하나만 알고 있어도 전체 클러스터에 연결할 수 있다
- 브로커 설정 중 listeners vs advertised.listeners
	- **`listeners`**: 브로커가 (또 다른 브로커로 부터)요청을 수신할 네트워크 주소와 포트 지정
		- 브로커들 사이에서 사용하는 주소
		- `listeners=PLAINTEXT://0.0.0.0:9092`: 9092 포트로 들어오는 모든 요청을 수신한다
		- Public IP일 필요 없음
	- **`advertised.listeners`**: 클라이언트가 브로커를 탐색하고 연결할 때 사용할 주소를 브로커가 광고함(advertise)
		- `advertised.listeners=PLAINTEXT://broker.mycompany.com:9092`
		- Public IP여야 한다
#### metadata update
- 클라이언트가 주기적으로 브로커에 연결해서 최신 메타데이터를 가져오는 과정
- 캐시된 메타데이터를 받아온 지 **일정 시간(metadata.max.age.ms)** 이 지날 떄 마다 요청을 보내서 메타데이터를 받아온다
	- "Updated cluster metadata version XXX to Cluster(nodes= XXX)..."

- **bootstrapping**, **metadata update**는 모든 클라이언트(프로듀서, 컨슈머)에게 공통되는 동작이다
- `org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after XXXX ms`
	- tcp/ip 연결은 성공했는데 메타데이터를 받아오지 못한 경우 발생
	- 많은 경우 카프카 보안 설정이 잘못되어서 그렇다
		- TLS, 권한 등 설정
#### metadata.max.age.ms를 짧게 잡으면 좋은 이유
- 클러스터의 최신 상태를 빠르게 받아올 수 있다
- 문제1: 메타데이터가 업데이트 되기전 리더/팔로워가 바뀌는 경우
	- `org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader`
		- 이 에러는 컨슈머가 재시도를 통해 다른 브로커에 요청을 보내므로 자연스럽게 해결된다
		- 재시도 설정을 끄는 경우에는 문제가 발생할 수 있긴함
- 문제2: 메타데이터가 업데이트되기전 브로커 전체 IP가 바뀌는 경우
	- 설정 값이 길면 클라이언트와 브로커의 연결이 끊어지고 장애가 발생한다
	- pod 환경에서 브로커를 띄우는 경우 발생할 가능성이 있다
- 기본은 5분, 많이 쓰는 값은 3분이다. 테스트를 통해 조정해야한다
## 9. Kafka metadata 동작 매커니즘: 브로커간 교환
- 브로커가 항상 최신 메타데이터를 가지고 있는 이유
	- 각각의 브로커가 전파해야 하는 사항을 주키퍼에 쓰면, 주키퍼를 감시하고 있는 전담 브로커(컨트롤러)가 전체 브로커에 전파한다
#### 컨트롤러
- 브로커 중 1대가 랜덤하게 컨트롤러 역할을 한다
	- 정상 동작중인 카프카 클러스텨 -> 컨트롤러가 정확하 1대있음
	- 레플리카의 리더와 팔로워 상태를 관리하고 전파한다
- 3가지 명령
	- LeaderAndIsr
		- 브로커 및 파티션 상태 전파
	- StopReplica
		- 복제 중지
	- UpdateMetadata
		- 최신 메타데이터 전파

## 10. KRaft
#### 컨트롤러는 **오염된 메타데이터**를 가질 수 있다
- 짧은 시간 내 여러 번의 변경이 발생했는데, UpdateMetadata 요청의 순서가 뒤집어진 경우
- 오염된 메타데이터를 가지고 있는 브로커가 컨트롤러를 물려 받는 경우
- 근본적인 원인은 **메타데이터의 기준점이 두 개**가 있다는 것이다
	- 주키퍼
	- 컨트롤러
#### 문제 해결
- 주키퍼를 없애고 컨트롤러 내부에 메타데이터를 저장한다
- 내고장성을 확보하기 위해 두 개이상의 컨트롤러에 메타데이터 저장
	- 쿼럼기반 컨트롤러
- 컨트롤러가 UpdateMetadata 요청을 보내주는 것이 아니라, 브로커가 컨트롤러로부터 메타데이터 업데이트 내역을 구독
	- 순서 반전 문제 해결

